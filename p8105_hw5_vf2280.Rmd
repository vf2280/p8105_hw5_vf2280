---
title: "Homework 5"
author: "Vasili Fokaidis"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(dplyr)
library(patchwork)
library(ggplot2)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Read in the data.

```{r}
homocide_df = 
  read_csv("homocide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )
  ) %>%
  select(city_state, resolved) %>%
  filter(city_state != "Tulsa_AL")
```

Let's look at this a bit

```{r}
aggregate_df =
homocide_df %>%
  group_by(city_state) %>%
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>%
  broom::tidy()
```

Try to iterate ........

```{r}
results_df =
aggregate_df %>%
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>%
  select(-prop_tests) %>%
  unnest(tidy_tests) %>%
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


## Problem 2

Importing one data set to see what data I'm working with and creating dataframe to store data.

```{r}
data_1 = read_csv("ldl_data/con_01.csv")
```

Creating a function to iterate over file names and read in data.

```{r}
data_read = function(df) {
 
  data = read_csv(df)

}
```

Iterating over all file names to read in data using `purrr:map` and saving variable in the dataframe.

```{r}
path_df =
  tibble(
    path = list.files("ldl_data")
  ) %>%
  mutate(
    path = str_c("ldl_data/", path),
    ldl_data = map(path, data_read)) %>%
  unnest(ldl_data)
  
```

Tidying the result into a new dataframe.

```{r}
ldl_df =
  path_df %>%
    mutate(
      subject_id = substring(path_df$path, 14, 15),
      arm = substring(path_df$path, 10, 12)) %>%
    select(arm, subject_id, week_1, week_2, week_3, week_4, week_5, week_6, week_7, week_8)

ldl_df
```

Spaghetti plot of observations on each subject from each arm over time.

```{r}
con_exp_plot =
  
ldl_df %>%
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "ldl"
  ) %>%
  mutate(
    week = substring(week, 6),
    week = as.numeric(week)
  ) %>%
  ggplot(aes(x = week, y = ldl, color = subject_id, linetype = arm))  +
  geom_point() +
  geom_line()+
  labs(
    title = "Experimental and Control Arm LDL Levels Over Time",
    x = "Week",
    y = "LDL Level"
    ) +
  theme_bw()

con_exp_plot
```

Separate spaghetti plots of observations on each subject from each arm over time.

```{r}
con_plot = 
  
  ldl_df %>%
  mutate(
    subject_id_arm = str_c(arm, subject_id)
  ) %>%
  select(-arm, -subject_id) %>%
  slice(-11:-20) %>%
   pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "ldl"
  ) %>%
  mutate(
    week = substring(week, 6),
    week = as.numeric(week)
  ) %>%
  ggplot(aes(x = week, y = ldl, color = subject_id_arm)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Control Arm LDL Levels Over Time",
    x = "Week",
    y = "LDL Level"
    ) +
  theme_bw()

exp_plot =
  
  ldl_df %>%
  mutate(
    subject_id_arm = str_c(arm, subject_id)
  ) %>%
  select(-arm, -subject_id) %>%
  slice(-1:-10) %>%
   pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "ldl"
  ) %>%
  mutate(
    week = substring(week, 6),
    week = as.numeric(week)
  ) %>%
  ggplot(aes(x = week, y = ldl, color = subject_id_arm)) +
  geom_point() +
  geom_line()+
   labs(
    title = "Experimental Arm LDL Levels Over Time",
    x = "Week",
    y = "LDL Level"
    ) + 
  theme_bw()

con_plot + exp_plot
```

The first spaghetti plot is rather busy making it hard to deduce  any observable difference between the control group and experimental group. But, by separating the two groups and plotting their data individually, we can see that the experimental group shows to have higher ldl levels over time. In terms of the study, without further information regarding the treatment for experimental subjects, it looks as though their treatment has raised ldl levels which normally is not good.


## Problem 3

Let's simulate 5000 datasets, where n = 30, mu = 0, and sigma = 5.

```{r, cache = TRUE}
sim_data = function(samp_size, mu = 0, sigma = 5) {
  
  data = 
  tibble(
    x = rnorm(n = samp_size, mean = mu, sd = sigma)
  )
  
   data %>%
    summarize(
      broom::tidy(t.test(x))
      ) %>%
     select(estimate, p.value)
}

output_0 = bind_rows(map(.x = 30, ~ rerun(5000, sim_data(.x))))

output_0 = 
  output_0 %>%
  tibble(
    mu = 0)

output_0
```

Repeat above for mu = {1, 2, 3, 4, 5, 6}

```{r, cache = TRUE}
mu = c(1, 2, 3, 4, 5, 6)

output_1 = vector("list", length = 6)

for(i in 1:6) {
  output_1[[i]] = rerun(5000, sim_data(30, mu = mu[[i]])) %>% 
    bind_rows()
}

output_1 = 
  output_1 %>%
  tibble(
    mu = c(1, 2, 3, 4, 5, 6)
  ) %>%
  unnest()

output_1
```

Final dataset containing tidy t-test values of simulaitons with specified sample size, mu values, and sigma value.

```{r}
output = bind_rows(output_0, output_1)

output
```

Function to find proportion based on mu value.

```{r}
prop_rej = function(x) {
  
output %>%
  filter(
    mu == x,
    p.value < 0.05
    ) %>%
  select(p.value) %>%
  nrow()/5000
  
}
```

Plot containing proportion of rejections of the null against each respective mu value.

```{r}
prop_rej_plot = 
  
  tibble(
    prop = map(unique(output$mu), prop_rej),
    mu = unique(output$mu)
  ) %>%
  unnest() %>%
  ggplot(aes(x = mu, y = prop, color = mu)) + 
  geom_point() +
  geom_line() +
  labs(
    title = "Proportion of Rejections of Null vs. Mu Value",
    x = "Mu Value",
    y = "Proportion of Rejections"
  ) +
  theme_bw()

prop_rej_plot
```

As the sample mean increases the power of the test also increases because the rejection of the null hypothesis happens more and more often.


Functions to make plots of average estimate of mu vs true value of mu and average estimate of mu hat where null is rejected vs true value of mu. 

```{r}
avg_estimate = function(x) {
  
output %>%
  filter(
    mu == x
  ) %>%
  select(
    estimate
    ) %>%
 sum()/5000
  
}

avg_estimate_rej = function(x) {
  
output %>%
  filter(
    mu == x,
    p.value < 0.05
    ) %>%
  select(estimate) %>%
  sum()/5000
  
}

```

Plots showing average estimate of mu hat vs the true value of mu and average estimate of mu hat where null is rejected vs true value of mu.  

```{r}
plot_avg_true = 
  
tibble(
    mu = unique(output$mu),
    avg_of_estimate = map(mu, avg_estimate)
  ) %>%
  unnest() %>%
  ggplot(aes(x = mu, y = avg_of_estimate, color = mu)) +
  geom_point() +
  labs(
    title = "Average Estimate of Mu Hat vs. the True Value of Mu",
    x = "True Mu",
    y = "Average Estimate of Mu Hat "
  ) +
  geom_line() +
  theme_bw()


plot_avg_rej_true = 
  
  tibble(
    mu = unique(output$mu),
    avg_of_rej_estimate = map(mu, avg_estimate_rej)
  ) %>%
  unnest() %>%
  ggplot(aes(x = mu, y = avg_of_rej_estimate, color = mu)) +
  geom_point() +
  labs(
    title = "Average Estimate of Mu Hat When Null is Rejected vs. the True Value of Mu",
    x = "True Mu",
    y = "Average Estimate of Mu Hat "
  ) +
  geom_line() +
  theme_bw()

plot_avg_true + plot_avg_rej_true
  
```

The sample average of mu hat across tests for which the null is rejected is not approximately equal to the true value of mu until the values of mu are larger than 3. This is because the amount of rejections increases as the sample average of mu hat increases, thus making the average closer to the respective mu value.